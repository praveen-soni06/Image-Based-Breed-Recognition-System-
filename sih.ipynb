{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcA+28zhT5w5u8XvolYTHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveen-soni06/Image-Based-Breed-Recognition-System-SIH-25004-/blob/main/sih.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XoGJXrqo2W4I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ0ZhZk92wR-",
        "outputId": "93da6790-4302-4808-fc7e-a8523b22a147"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0de0163d10>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEVICE\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6AAp33Q2xXQ",
        "outputId": "aab899af-eb4c-4aff-f60b-0631ff62302d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iIh5TEBP22JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/My Drive/cow_datasets\"\n",
        "print(os.listdir(data_path))"
      ],
      "metadata": {
        "id": "Wj1kSXiF3GGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for breed_folder in os.listdir(data_path):\n",
        "    breed_path = os.path.join(data_path, breed_folder)\n",
        "    if os.path.isdir(breed_path):\n",
        "        for image_name in os.listdir(breed_path):\n",
        "            img_path = os.path.join(breed_path, image_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (224, 224))  # Bigger size for ResNet\n",
        "                images.append(img)\n",
        "                labels.append(breed_folder)\n",
        "\n",
        "X = np.array(images, dtype=\"float32\") / 255.0\n",
        "y = np.array(labels)\n"
      ],
      "metadata": {
        "id": "Et-reBHM3SBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "num_classes = len(np.unique(y))"
      ],
      "metadata": {
        "id": "WBvQ_aMr3TCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "ZDIviXKP3VCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSFORMS\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "UD1tr71t3ZCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUSTOM DATASET\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels, transform=None):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.features[idx].astype(np.uint8)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "rvJwBXEN3cY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=train_transform)\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=test_transform)"
      ],
      "metadata": {
        "id": "TYrlyehe3eqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Replace final layer\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "nRy4hjb23g08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS, OPTIMIZER, SCHEDULER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ],
      "metadata": {
        "id": "Z-C30pgE3jaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING LOOP\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "ZFk7NfN13l_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "FC2V1LKB4AVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION FUNCTION\n",
        "def evaluate(model, loader, device):\n",
        "    correct_top1, correct_top3, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            _, top3_preds = outputs.topk(3, 1)\n",
        "            correct_top1 += (preds == labels).sum().item()\n",
        "            for i in range(labels.size(0)):\n",
        "                if labels[i] in top3_preds[i]:\n",
        "                    correct_top3 += 1\n",
        "            total += labels.size(0)\n",
        "    return 100*correct_top1/total, 100*correct_top3/total"
      ],
      "metadata": {
        "id": "AnXzc3Ue3rZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE\n",
        "test_top1, test_top3 = evaluate(model, test_loader, device)\n",
        "train_top1, train_top3 = evaluate(model, train_loader, device)\n",
        "\n",
        "print(f\"Test Set - Top-1 Accuracy: {test_top1:.2f}%, Top-3 Accuracy: {test_top3:.2f}%\")\n",
        "print(f\"Train Set - Top-1 Accuracy: {train_top1:.2f}%, Top-3 Accuracy: {train_top3:.2f}%\")"
      ],
      "metadata": {
        "id": "ZyU17vBa3uWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SINGLE IMAGE PREDICTION\n",
        "def predict_breed(model, img_path, device, label_encoder):\n",
        "    model.eval()\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "    ])\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_tensor)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "    breed_name = label_encoder.inverse_transform(pred.cpu().numpy())[0]\n",
        "    return breed_name\n",
        "\n",
        "\n",
        "predicted_breed = predict_breed(model, \"/content/drive/My Drive/cow_datasets/Breed1/img1.jpg\", device, le)\n",
        "print(\"Predicted Breed:\", predicted_breed)"
      ],
      "metadata": {
        "id": "VPDaAvQd3wkf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}